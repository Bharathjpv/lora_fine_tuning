{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google/vit-base-patch16-224-in21k'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jpv/Bharath_J_P_V/Personal_Projects/lora_fine_tuning/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "from peft import PeftModel, LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "\n",
    "def print_model_size(path):\n",
    "    size = 0\n",
    "    for f in os.scandir(path):\n",
    "        size += os.path.getsize(f)\n",
    "\n",
    "    print(f\"Model size: {(size / 1e6):.2} MB\")\n",
    "\n",
    "\n",
    "def print_trainable_parameters(model, label):\n",
    "    parameters, trainable = 0, 0\n",
    "    \n",
    "    for _, p in model.named_parameters():\n",
    "        parameters += p.numel()\n",
    "        trainable += p.numel() if p.requires_grad else 0\n",
    "\n",
    "    print(f\"{label} trainable parameters: {trainable:,}/{parameters:,} ({100 * trainable / parameters:.2f}%)\")\n",
    "\n",
    "\n",
    "def split_dataset(dataset):\n",
    "    dataset_splits = dataset.train_test_split(test_size=0.1)\n",
    "    return dataset_splits.values()\n",
    "    \n",
    "\n",
    "def create_label_mappings(dataset):\n",
    "    label2id, id2label = dict(), dict()\n",
    "    for i, label in enumerate(dataset.features[\"label\"].names):\n",
    "        label2id[label] = i\n",
    "        id2label[i] = label \n",
    "\n",
    "    return label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 10.5k/10.5k [00:00<00:00, 22.8MB/s]\n",
      "Downloading data: 100%|██████████| 490M/490M [00:43<00:00, 11.1MB/s] \n",
      "Downloading data: 100%|██████████| 464M/464M [00:38<00:00, 12.0MB/s] \n",
      "Downloading data: 100%|██████████| 472M/472M [00:39<00:00, 12.1MB/s] \n",
      "Downloading data: 100%|██████████| 464M/464M [00:38<00:00, 12.1MB/s] \n",
      "Downloading data: 100%|██████████| 475M/475M [00:43<00:00, 11.0MB/s] \n",
      "Downloading data: 100%|██████████| 470M/470M [00:42<00:00, 11.2MB/s] \n",
      "Downloading data: 100%|██████████| 478M/478M [00:39<00:00, 12.0MB/s] \n",
      "Downloading data: 100%|██████████| 486M/486M [00:40<00:00, 11.9MB/s] \n",
      "Downloading data: 100%|██████████| 423M/423M [00:34<00:00, 12.1MB/s] \n",
      "Downloading data: 100%|██████████| 413M/413M [00:38<00:00, 10.9MB/s] \n",
      "Downloading data: 100%|██████████| 426M/426M [00:35<00:00, 12.1MB/s] \n",
      "Generating train split: 100%|██████████| 75750/75750 [00:02<00:00, 27537.62 examples/s]\n",
      "Generating validation split: 100%|██████████| 25250/25250 [00:00<00:00, 28578.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This is the food dataset\n",
    "dataset1 = load_dataset(\"food101\", split=\"train[:10000]\")\n",
    "\n",
    "# This is the datasets of pictures of cats and dogs.\n",
    "# Notice we need to rename the label column so we can\n",
    "# reuse the same code for both datasets.\n",
    "# dataset2 = load_dataset(\"microsoft/cats_vs_dogs\", split=\"train\", trust_remote_code=True)\n",
    "# dataset2 = dataset2.rename_column(\"labels\", \"label\")\n",
    "\n",
    "dataset1_train, dataset1_test = split_dataset(dataset1)\n",
    "# dataset2_train, dataset2_test = split_dataset(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_label2id, dataset1_id2label = create_label_mappings(dataset1)\n",
    "# dataset2_label2id, dataset2_id2label = create_label_mappings(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = {\n",
    "        \"train_data\": dataset1_train,\n",
    "        \"test_data\": dataset1_test,\n",
    "        \"label2id\": dataset1_label2id,\n",
    "        \"id2label\": dataset1_id2label,\n",
    "        \"epochs\": 5,\n",
    "        \"path\": \"./lora-model1\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "preprocess_pipeline = Compose([\n",
    "    Resize(image_processor.size[\"height\"]),\n",
    "    CenterCrop(image_processor.size[\"height\"]),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=image_processor.image_mean, std=image_processor.image_std),\n",
    "])\n",
    "\n",
    "def preprocess(batch):\n",
    "    batch[\"pixel_values\"] = [\n",
    "        preprocess_pipeline(image.convert(\"RGB\")) for image in batch[\"image\"]\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1[\"train_data\"].set_transform(preprocess)\n",
    "model1[\"test_data\"].set_transform(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
